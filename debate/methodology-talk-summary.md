# Debate Summary: Methodology Talk Angle for Agentic Dev Days 2026

## Participants
- **Claude** (Opus 4.6): Proposer/defender
- **Codex** (GPT-5.3): Adversarial reviewer

## Rounds
- Round 0: Claude draft + self-review
- Round 1: Codex critique → Claude response
- Round 2: Codex rebuttal (final)

## Consensus Reached

**Both sides agree:**

1. **The methodology angle IS stronger than the AXON-language angle** for a dev conference audience — it has real outcomes and is more transferable
2. **Submit one methodology-first lightning talk (10 min)** with AXON as minimal case study (10-20% of airtime)
3. **Do NOT submit a 30-minute methodology talk** without prospective pre-registered evidence
4. **Frame as "agentic workflow design pattern"** — not autonomous breakthrough, not just clever tool use
5. **Use hybrid demo format** — pre-recorded truth run with annotated replay, not fully live multi-round debate
6. **n=1 is acceptable only as practitioner pilot report** — no generalization claims
7. **Do NOT submit two separate lightning talks** from the same project (cannibalization risk)

## Concessions Accepted by Both Sides

| Point | Claude conceded | Codex accepted |
|-------|----------------|----------------|
| Recency/optimism bias in draft | Yes (C1) | Genuine, adequate |
| "Immediately actionable" overstated | Yes (C2) | Genuine, adequate |
| n=1 cannot support method claims | Yes (C3) | Genuine, adequate |
| Fully live demo is operationally risky | Yes (C4) | Genuine, adequate |
| 30-min methodology talk is premature | Yes (C5) | Genuine, adequate |

## Defenses Accepted by Codex

| Defense | Codex verdict |
|---------|---------------|
| Methodology genuinely stronger than AXON angle (D1) | Valid, conditional on AXON staying minimal |
| "Agentic" framing holds when scoped (PC1) | Valid with human-in-the-loop framing |
| Distinctiveness vs competition (D2) | Partially valid — concession mechanics are differentiator |

## Unresolved Issues

1. **"Stronger" is underspecified** — by what metric? Acceptance odds, audience utility, or project leverage?
2. **"Make Claude and Codex fight" framing risks looking like theatrics** — needs reliability outcomes foregrounded
3. **Decision discipline** — Claude introduced multiple submission strategies after convergence was reached

## Combined Verdict (Both Debates)

Across both debates, the final recommendation is:

**Submit ONE talk: a 10-minute methodology-first lightning talk.**

- Title angle: "Structured adversarial AI review as a reliability pattern"
- 80-90% methodology, 10-20% AXON as case study
- Hybrid demo (pre-recorded + optional tiny live element)
- Explicit epistemic boundaries: "pilot from one project, transferable protocol hypothesis"
- Foreground reliability outcomes (bugs found, design flaws caught), not the spectacle of models fighting

## Debate Files

1. `debate/methodology-talk-claude-draft.md`
2. `debate/methodology-talk-claude-self-review.md`
3. `debate/methodology-talk-codex-critique.md`
4. `debate/methodology-talk-claude-response-1.md`
5. `debate/methodology-talk-codex-rebuttal-1.md`
6. `debate/methodology-talk-summary.md`

## Costs
| Invocation | Tokens (in/out) | API cost | Wall-clock time | Model version |
|------------|-----------------|----------|-----------------|---------------|
| Codex R1   | ~68k / ~4k      | ~$1.00   | ~120s           | gpt-5.3-codex |
| Codex R2   | ~49k / ~2k      | ~$0.70   | ~90s            | gpt-5.3-codex |
